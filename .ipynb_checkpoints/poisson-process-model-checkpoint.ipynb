{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Turing\n",
    "using MCMCChains\n",
    "using Plots\n",
    "using StatsPlots\n",
    "using StatsBase\n",
    "using Distributions\n",
    "using NPZ\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267759-element Vector{Float64}:\n",
       "   15.982835732952108\n",
       "   15.992836839228154\n",
       "   16.0028379455042\n",
       "   16.012839051780247\n",
       "   16.022840158056297\n",
       "   16.03284126433234\n",
       "   16.042842370608387\n",
       "   16.052843476884433\n",
       "   16.06284458316048\n",
       "   16.072845689436527\n",
       "   16.082846795712577\n",
       "   16.092847901988623\n",
       "   16.10284900826467\n",
       "    ⋮\n",
       " 2693.748894411977\n",
       " 2693.7588955182528\n",
       " 2693.768896624529\n",
       " 2693.778897730805\n",
       " 2693.7888988370814\n",
       " 2693.7988999433574\n",
       " 2693.8089010496333\n",
       " 2693.8189021559097\n",
       " 2693.828903262185\n",
       " 2693.8389043684615\n",
       " 2693.8489054747374\n",
       " 2693.8589065810133"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"spikeAndBehavioralData/allData/Cori_2016-12-14/\"\n",
    "eye_area = npzread(\"$(data_path)eye.area.npy\")\n",
    "clusterids = npzread(\"$(data_path)spikes.clusters.npy\")[:] \n",
    "spiketimes = npzread(\"$(data_path)spikes.times.npy\")[:]\n",
    "eyetimes = npzread(\"$(data_path)eye.timestamps.npy\")[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing ##\n",
    "\n",
    "The first step is to process the data for when each cluster spikes into an array. Each row should represent a cluster and each column should represent a time bin. Each entry to the array is the amount of times that that particular neuron spiked over the period of the time bin (e.g. 1 second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count spikes for each cluster\n",
    "unique_clusterids = sort(unique(clusterids))\n",
    "nclusters = length(unique_clusterids) # number of clusters\n",
    "binedges = -0.5 .+ append!(unique_clusterids,clusterids[end]+1)\n",
    "h_spikecounts = StatsBase.fit(Histogram,clusterids[:],binedges)\n",
    "spikecounts = h_spikecounts.weights\n",
    "spikerates = spikecounts./maximum(spiketimes)\n",
    "\n",
    "# get spike counts per timebin\n",
    "dt = 1 # seconds\n",
    "maxtime = maximum(spiketimes)\n",
    "timebin_edges = (20:dt:maxtime-20)\n",
    "nt = length(timebin_edges)\n",
    "spikecount_matrix = Array{Int64}(undef,nclusters,nt-1)\n",
    "\n",
    "for i = 1:nclusters\n",
    "    inds = findall(clusterids.==i)\n",
    "    htemp = StatsBase.fit(Histogram,spiketimes[:][inds],timebin_edges)\n",
    "    spikecount_matrix[i,:] = htemp.weights\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to reformat the eye area data to rescale the time frame. This is necessary as the eye area data was captured using a camera the cluster spiketimes was captured using a neuropixel probe, meaning that although they record for the same time period, the time scales are incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all negative areas from the eye_area data\n",
    "for i in 1:length(eye_area)\n",
    "    if eye_area[i] < 0\n",
    "        eye_area[i] = 0\n",
    "    end\n",
    "end\n",
    "\n",
    "# Define the bounderies for the timebins for eye areas\n",
    "dt = 1 # seconds\n",
    "maxtime = maximum(spiketimes)\n",
    "timebin_edges = (20:dt:maxtime-20)\n",
    "nt = length(timebin_edges)\n",
    "eye_area_bin = zeros(Float32, nt-1)\n",
    "\n",
    "# Generate the average eye area for each time bin.\n",
    "j = 1\n",
    "for i in 1:nt-1\n",
    "    count = 0\n",
    "    while eyetimes[j] <= timebin_edges[i+1]\n",
    "        if eyetimes[j] >= timebin_edges[i]\n",
    "            eye_area_bin[i] += eye_area[j]\n",
    "            count += 1\n",
    "        end\n",
    "        j += 1\n",
    "    end\n",
    "    eye_area_bin[i] /= count\n",
    "end\n",
    "\n",
    "plot(eye_area_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now left with eye area averages which correspond to the same time period as each spikecount for each neuron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikecount_matrix[cluster index, time bin index]\n",
    "n_clusters = length(spikecount_matrix[:,1])\n",
    "n_timebins = length(spikecount_matrix[1,:])\n",
    "\n",
    "println(\"The number of clusters is $(n_clusters)\")\n",
    "println(\"Number of timebins is $(n_timebins)\")\n",
    "\n",
    "summed_spikecounts = zeros(Float32, length(spikecount_matrix[1,:]))\n",
    "for cluster in 1:length(spikecount_matrix[:,1])\n",
    "    summed_spikecounts += spikecount_matrix[cluster,:]\n",
    "end\n",
    "\n",
    "average_spikecounts = summed_spikecounts ./ length(spikecount_matrix[:,1])\n",
    "\n",
    "println(\"There is a Pearson correlation coefficient of \", cor(average_spikecounts, eye_area_bin), \" between the two data\")\n",
    "\n",
    "plot(eye_area_bin, label=\"eye area\")\n",
    "plot!(average_spikecounts, label=\"averaged spikecounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikecount_array = []\n",
    "# Turn the matrix into a vector\n",
    "for i in 1:n_clusters\n",
    "    spikecount_array = cat(dims=1, spikecount_array, spikecount_matrix[i,:])\n",
    "end\n",
    "\n",
    "# Check that the logic of inlining the matrix is correct\n",
    "@assert spikecount_array[1:n_timebins] == spikecount_matrix[1,:]\n",
    "@assert length(spikecount_array) == n_clusters*n_timebins\n",
    "\n",
    "# Create ids to label each spikecount\n",
    "cluster_ids = [i for i in 1:n_clusters for j in 1:n_timebins]\n",
    "timebin_ids = [j for i in 1:n_clusters for j in 1:n_timebins]\n",
    "\n",
    "# Normalise eye area\n",
    "eye_area_bin = eye_area_bin ./ std(eye_area_bin; dims=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "$$y_{i, j} \\sim Poisson(\\lambda_{i,j})$$\n",
    "\n",
    "$$\\lambda_{i,j} = exp(\\alpha + \\alpha_i * eye\\_area_j \\cdot \\beta_j \\cdot \\tau_\\beta)$$\n",
    "\n",
    "$$\\alpha \\sim Normal(mean(y), std(y))$$\n",
    "\n",
    "$$\\alpha_i \\sim Normal(0, \\tau_\\alpha)$$\n",
    "\n",
    "$$\\beta_j \\sim Normal(0, 1)$$\n",
    "\n",
    "$$\\tau_\\alpha \\sim Cauchy^+(0, 2)$$\n",
    "\n",
    "$$\\sigma \\sim Exponential(1/std(y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function firing_model(spikecount_array, cluster_ids, timebin_ids, eye_area_bin, n_clusters, n_timebins)\n",
    "\n",
    "    # Priors\n",
    "    # α ~ Normal(mean(spikecount_array), 2.5 * std(spikecount_array))\n",
    "    β ~ Normal(0, 1)\n",
    "\n",
    "    τ_α ~ truncated(Cauchy(0, 2), 0, Inf)\n",
    "    τ_β ~ truncated(Cauchy(0, 2), 0, Inf)\n",
    "    α_i ~ filldist(Gamma(2, 2), n_clusters)\n",
    "    β_i ~ filldist(Gamma(2, 2), n_clusters)\n",
    "\n",
    "    for i in 1:n_clusters\n",
    "        for j in 1:n_timebins\n",
    "            λ = τ_α * α_i[cluster_ids[i]] + eye_area_bin[timebin_ids[j]] * β_i[cluster_ids[i]] * τ_β\n",
    "            spikecount_array[((i-1)*n_timebins)+j] ~ Poisson(λ)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return spikecount_array \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = firing_model(spikecount_array, cluster_ids, timebin_ids, eye_area_bin, n_clusters, n_timebins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = sample(model, NUTS(0.65), MCMCThreads(), 1000, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
